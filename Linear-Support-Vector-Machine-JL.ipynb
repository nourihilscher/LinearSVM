{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e48efb",
   "metadata": {},
   "source": [
    "# Linear SVM (Julia Implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b3a6a",
   "metadata": {},
   "source": [
    "We are trying to solve a problem of binary classification. Lets assume we are given a set $S$ of $n \\in \\mathbb{N}$ datapoints $x_k \\in \\mathbb{R}^m$ with corresponding labels $y_k \\in \\{-1, 1\\}$ (for our implementations it does not really matter whether the labels are given in that form as long as there are just binary labels with 1 beeing the positive case, but assuming this makes the derivation easier). Our goal is to build and train a **Support Vector Machine** (SVM) which can be used to predict labels of new datapoints. In contrast to most other methods we will try to achive this by using linear optimzation (Simplex Algorithm).  \n",
    "\n",
    "For notation purposes we denote the set of all $x_k \\in S$ with $y_k = 1$ as $S^+$ and the set of all $x_k = -1$ as $S^-$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f71143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalation and Setup\n",
    "# import Pkg\n",
    "# Pkg.add(\"JuMP\")\n",
    "# Pkg.add(\"GLPK\")\n",
    "using JuMP, GLPK\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de402a1",
   "metadata": {},
   "source": [
    "### Finding one seperating hyperplane\n",
    "The following algorithm aims to find any seperating hyperplane of the form $a^T x = \\beta, a \\in \\mathbb{R}^m, \\beta \\in \\mathbb{R}$ (with $a^T x_k \\geq \\beta$ if $x_k \\in S^+$ and $a^T x_k \\leq \\beta$ if $x_k \\in S^-$) to split the data into two half-spaces.  \n",
    "**Why does it work?**: The Simplex Algorithm is only able to solve linear optimization problems with constraints that form a polyhedron. We can view the set of all hyperplanes which seperate our data as $H = \\{(a, \\beta) \\in \\mathbb{R}^{m+1} | a^T x - \\beta \\leq 0, \\forall x \\in S^+ \\text{ and } a^T x - \\beta \\geq 0, \\forall x \\in S^- \\}$ (we add a Restriction for every point in our provided dataset) which is clearly a polyhedron. Now optimizing over the linear objective function $0^T a + 0 \\cdot \\beta$ will provide one seperating hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91faa2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input: data dict of the form [\"label\": 1/0 or 1/-1 or..., \"x\": vector]\n",
    "# Output: (a, beta) which seperate our data\n",
    "function findHyperplane(data)\n",
    "    model = Model(GLPK.Optimizer)\n",
    "\n",
    "    set_optimizer_attribute(model, \"msg_lev\", GLPK.GLP_MSG_ALL)\n",
    "    @variable(model, a[1:data[1].length])\n",
    "    @variable(model, beta)\n",
    "    for i in data\n",
    "        # CHANGE: Change this if labels do not equal 1 fo good\n",
    "        if i[\"label\"] == 1\n",
    "            @constraint(model, a' * i[\"x\"] <= beta) \n",
    "         else\n",
    "            @constraint(model, a' * i[\"x\"] >= beta)\n",
    "         end\n",
    "    end\n",
    "    @objective(model, Max, 0)\n",
    "    JuMP.optimize!(model)\n",
    "    return (JuMP.value.(a), JuMP.value.(beta))\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f1b31",
   "metadata": {},
   "source": [
    "### Findind a seperating hyperplane with maximal distance SVM\n",
    "The following algorithm aims to find the seperating hyperplane with maximal distance (messured in the 1-Norm so we are able to linearize the problem) to points in the sets $S^+$ and $S^-$.  \n",
    "**Why does it work?**: Our goal now is to maximize the distance between any point in $S^+$ or $S^-$ and our seperating hyperplane. We can solve this problem by creating two seperating hyperplanes given by the same vector $a$ but different levels $\\beta_-$ and $\\beta_+$. The level of the hyperplane that maximizes the distance (in the 1 norm) between points in the sets $S^+$ and $S^-$ is than given by $\\frac{1}{2} \\beta_- - \\beta_+$. Adding the constraints $a^T x \\leq \\beta_+$, $a^T x \\geq \\beta_-$ and maximizing the distance between both hyperplanes $\\beta_- - \\beta_+$ achives this. It follows from the Hölder-Inequality that requiring $\\|a\\|_{\\infty} = 1$ (or as a linear constraint $-1 \\leq a_i \\leq 1$) ensures actually maximizing the L1 distance between points in $S^+$ / $S^-$ and the seperating hyperplane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: data dict of the form [\"label\": 1/0 or 1/-1 or..., \"x\": vector]\n",
    "# Output: (a, beta) which seperate our data optimally\n",
    "function findHyperplane(data)\n",
    "    model = Model(GLPK.Optimizer)\n",
    "\n",
    "    set_optimizer_attribute(model, \"msg_lev\", GLPK.GLP_MSG_ALL)\n",
    "    @variable(model, a[1:data[1].length])\n",
    "    @variable(model, beta[1:2])\n",
    "    for i in data\n",
    "        # CHANGE: Change this if labels do not equal 1 fo good\n",
    "        if i[\"label\"] == 1\n",
    "            @constraint(model, a' * i[\"x\"] <= beta[1]) \n",
    "         else\n",
    "            @constraint(model, a' * i[\"x\"] >= beta[2])\n",
    "         end\n",
    "    end\n",
    "    @constraint(model, -1 .<= a .<= 1)\n",
    "    @objective(model, Max, 1/2 * (beta[2] - beta[1]))\n",
    "    JuMP.optimize!(model)\n",
    "    return (JuMP.value.(a), JuMP.value.(beta))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
